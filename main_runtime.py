import csv
from openai import OpenAI
import re
import os
import openai

BUGS_CSV_FILE = "error_list.csv"

BUGS_DIR = "runtime_errors"
LLM_BUG_RESPONSES_DIR = "llm_response"
PROMPT = "prompt"
LLM_BUG_SUMMARY_DIR = "llm_bug_summary"

OPENAI_TOKEN_FILE = "OPENAI_TOKEN"

# AI_MODEL = "gpt-3.5-turbo"
# AI_MODEL = "gpt-4o"
AI_MODEL = "o3-mini"


SYSTEM_PROMPT = """You are a helpful assistant which debugs RTL and HDL code in Verilog and VHDL. Do not provide code in your answer. Explain what has gone wrong and why a bug is occurring, but do not attempt to fix the bug yourself."""


#  this prompts without error line
#  What is the bug and why is it occurring?",
# USER_PROMPTS = [
#     "Error message: %s\n\nObserved behavior: %s\n\nFull code file:```%s```\n\nTestbench Code:```%s```\n\nWhat is the bug, why is it occurring, and how can it be fixed?"
# ]

USER_PROMPTS = [
    """Error message: %s\n\nFull code file:```%s```\n\nTestbench Code:```%s```\n\nWhat is the bug, why is it occurring, and how can it be fixed?\n
    Note: this error occurred during the simulation of the test bench and code file below. It is an error message generated by the test bench itself. You should determine the root cause of the issue and explain the fix.
    """
]


def main():
    #load the OpenAI token
    with open(OPENAI_TOKEN_FILE, 'r') as file:
        openai_token = file.read().strip()

    client = OpenAI(api_key=openai_token)
    client.organization = "org-PhuZaSvz3L7YWrH38mnU5ybq"

    #load the bugs
    with open(BUGS_CSV_FILE, 'r') as file:
        reader = csv.DictReader(file)
        bugs_data = [row for row in reader]

    #for each bug
    for bug in bugs_data:
        # ensure that the error messages are correct wrt line numbers
        if bug["Error Message"] == "No Error Message":
            continue

        print(bug["Bug ID"], ": ", bug["Type of Bug"])

        #load the buggy file
        with open(f"{BUGS_DIR}/bug_{bug['Bug ID']}/rtl/{bug['File Name']}", 'r') as file:
            buggy_code = file.read()
        
        #read through the testbench
        testbench_name = f"tb_top{bug['Bug ID']}_module.v"
        with open(f"{BUGS_DIR}/bug_{bug['Bug ID']}/testbench/{testbench_name}", 'r', encoding='utf-8') as file:
            testbench = file.read()


        content = [
            (bug["Error Message"], buggy_code, testbench),
        ]

        for j in range(len(USER_PROMPTS)):
            # output a txt file with all errors and easy to compare
            # using the prompt to as sevel times

            # save the prompt - input
            # with open(f"{PROMPT}/bug_{bug['Bug ID']}.txt", 'a', encoding="utf-8") as file:
            #     file.write(f"system: {SYSTEM_PROMPT} \n\n user: {USER_PROMPTS[j] % content[j]} \n")

            for i in range(5):
                # check if the file have been check or not
                if os.path.exists(f"{BUGS_DIR}/bug_{bug['Bug ID']}/{LLM_BUG_RESPONSES_DIR}/bug_{bug['Bug ID']}_llm_{AI_MODEL}_iteration_{i}.txt"):
                    continue
                # get prompt index
                # prompt_index = USER_PROMPTS.index(prompt)


                #send the messages to the OpenAI API
                response = client.chat.completions.create(
                    model= AI_MODEL,
                    # messages=
                    messages=[
                        {"role": "user", "content": SYSTEM_PROMPT},  # Use 'user' instead of 'system' for the prompt
                        {"role": "user", "content": USER_PROMPTS[j] % content[j]}
                    ]
                )

                #print the response
                # print(response.choices[0].message.content)
                #save the response
                with open(f"{BUGS_DIR}/bug_{bug['Bug ID']}/{LLM_BUG_RESPONSES_DIR}/bug_{bug['Bug ID']}_llm_{AI_MODEL}_iteration_{i}.txt", 'w', encoding="utf-8") as file:
                    file.write(str(response.choices[0].message.content))

                # with open(f"{LLM_BUG_SUMMARY_DIR}/bug_{bug['Bug ID']}_ide_{bug['IDE']}_llm_{AI_MODEL}.txt", 'a', encoding="utf-8") as file:
                #     # Write new content to the file
                #     file.write(f"{str(response.choices[0].message.content)} \n")
                #     file.write("\n")
    
if __name__ == "__main__":
    main()