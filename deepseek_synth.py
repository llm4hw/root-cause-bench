import csv
from openai import OpenAI
import re
import os
# import pandas as pd
import openai

BUGS_CSV_FILE = r"D:\UNSW\chip chat\newnewnew\error_list_synth.csv"

BUGS_DIR = r"D:\UNSW\chip chat\newnewnew\synthesis_errors"
LLM_BUG_RESPONSES_DIR = "llm_response"
PROMPT = r"D:\UNSW\chip chat\newnewnew\prompt"

DEEPSEEK_TOKEN = "sk-a01ffd2abe174fa3a752654409f76acf"

AI_MODEL = "deepseekR1"

# --- Prompt design ---
# SYSTEM_PROMPT = """You are a helpful assistant which debugs RTL and HDL code in Verilog and VHDL. Do not provide code in your answer. Explain what has gone wrong and why a bug is occurring, but do not attempt to fix the bug yourself."""

# --- Prompt design ---
SYSTEM_PROMPT = """You are a helpful assistant which debugs RTL and HDL code in Verilog and VHDL. Do not provide code in your answer. Explain what has gone wrong and why a bug is occurring, but do not attempt to fix the bug yourself."""


#  this prompts without error line
#  What is the bug and why is it occurring?",
USER_PROMPTS = [
    """"Error message: %s\n\nError line:```%s```\n\nFull code file:```%s```\n\nWhat is the bug, why is it occurring, and how can it be fixed?\n
    Note: this error occurred during the simulation of the test bench and code file below. It is an error message generated by the test bench itself. You should determine the root cause of the issue and explain the fix.
    """
]

#a vivado error message looks like this
#ERROR: [Synth 8-2715] syntax error near elsif [D:/chip chat/bugs/vivado_vhdl_bug_1/vivado_vhdl_bug_1.srcs/sources_1/new/Syntax_Errors.vhd:47]
#we want to extract the line number
vivado_filetype_error_line_re = re.compile(r"\.(vhd|v|vhdl):([0-9]+)]")

def main():
    #load the OpenAI token
    # with open(OPENAI_TOKEN_FILE, 'r') as file:
    #     openai_token = file.read().strip()

    # client = OpenAI(api_key=OPENAI_TOKEN)
    # client.organization = "org-PhuZaSvz3L7YWrH38mnU5ybq"
    client = OpenAI(api_key=DEEPSEEK_TOKEN, base_url="https://api.deepseek.com") # modify in this line
    # client.organization = "org-PhuZaSvz3L7YWrH38mnU5ybq"

    #load the bugs
    with open(BUGS_CSV_FILE, 'r') as file:
        reader = csv.DictReader(file)
        bugs_data = [row for row in reader]

    #for each bug
    for bug in bugs_data:
        # ensure that the error messages are correct wrt line numbers
        if bug["Error Message"] == "No Error Message":
            continue
        ###
        ###
        # if bug["Bug ID"] == "1" or bug["Bug ID"] == "2" or bug["Bug ID"] == "3" or bug["Bug ID"] == "4":
        #     continue
        ###
        ###
        ###
        print(bug["Bug ID"], ": ", bug["Type of Bug"])

        #load the buggy file
        with open(f"{BUGS_DIR}/bug_{bug['Bug ID']}/rtl/{bug['File Name']}", 'r') as file:
            buggy_code = file.read()
        
        #extract the error line
        error_line = ""
        if bug["IDE"] == "Vivado":
            try:
                # Code that may raise the AttributeError
                error_line_no = vivado_filetype_error_line_re.search(bug["Error Message"]).group(2)
                error_line = buggy_code.split("\n")[int(error_line_no)-1]
            except AttributeError:
                # Handle the AttributeError
                error_line = "no error - can be complication"  # Or any other default value or behavior

        content = [
            (bug["Error Message"], error_line, buggy_code),
        ]

        for j in range(len(USER_PROMPTS)):
            # output a txt file with all errors and easy to compare
            # using the prompt to as sevel times
            for i in range(5):
                # check if the file have been check or not
                if os.path.exists(f"{BUGS_DIR}/bug_{bug['Bug ID']}/{LLM_BUG_RESPONSES_DIR}/bug_{bug['Bug ID']}_llm_{AI_MODEL}_iteration_{i}.txt"):
                    continue
                # get prompt index
                # prompt_index = USER_PROMPTS.index(prompt)

                #send the messages to the OpenAI API
                response = client.chat.completions.create(
                    model= "deepseek-reasoner",
                    # messages=
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},  # Use 'user' instead of 'system' for the prompt
                        {"role": "user", "content": USER_PROMPTS[j] % content[j]}
                    ],
                    n = 1
                )

                #print the response
                # print(response.choices[0].message.content)
                #save the response
                with open(f"{BUGS_DIR}/bug_{bug['Bug ID']}/{LLM_BUG_RESPONSES_DIR}/bug_{bug['Bug ID']}_llm_{AI_MODEL}_iteration_{i}.txt", 'w', encoding="utf-8") as file:
                    file.write(str(response.choices[0].message.content))

                # with open(f"{LLM_BUG_SUMMARY_DIR}/bug_{bug['Bug ID']}_ide_{bug['IDE']}_prompt_{PROMPT_STRATEGY[j]}_llm_{AI_MODEL}.txt", 'a', encoding="utf-8") as file:
                #     # Write new content to the file
                #     file.write(f"{str(response.choices[0].message.content)} \n")
                #     file.write("\n")
    
if __name__ == "__main__":
    main()